{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "baf5d011",
      "metadata": {
        "id": "baf5d011"
      },
      "source": [
        "# Golden Dataset Construction  \n",
        "**Extraction → Label Expansion → Cleaning**\n",
        "\n",
        "This notebook consolidates the Golden Dataset workflow used in the capstone project: *System Risk in Policy-Driven AI Systems*.\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "The Golden Dataset is a governance-aligned evaluation subset designed to expose\n",
        "system-level risks that are hidden by legacy labels.\n",
        "\n",
        "This notebook includes two stages:\n",
        "\n",
        "1. **Extraction / Sampling**  \n",
        "   Selection of a small, governance-focused subset from the Civil Comments dataset\n",
        "   (high-risk, borderline, and clean tiers).\n",
        "\n",
        "2. **Label Expansion & Cleaning**  \n",
        "   Transformation of human annotations into analysis-ready columns, including:\n",
        "   - binary harm labels  \n",
        "   - ambiguity codes  \n",
        "   - cleaned export schema  \n",
        "\n",
        "---\n",
        "\n",
        "## Reproducibility & Ethics\n",
        "To keep this repository ethical and lightweight, **raw datasets are not included**.\n",
        "\n",
        "You must provide the Civil Comments source file locally (or via Drive) and specify\n",
        "your own input and output paths below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819581c7",
      "metadata": {
        "id": "819581c7"
      },
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Display tweaks (optional)\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 120)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37be1047",
      "metadata": {
        "id": "37be1047"
      },
      "source": [
        "## Setup and Paths\n",
        "\n",
        "This notebook assumes access to the Civil Comments dataset under its original\n",
        "licensing terms.\n",
        "\n",
        "Raw datasets are not included in this repository. Users must supply their own\n",
        "local or Drive-based paths for input and output files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e7cd87",
      "metadata": {
        "id": "b0e7cd87"
      },
      "outputs": [],
      "source": [
        "# Civil Comments source for sampling/extraction ---\n",
        "CIVIL_COMMENTS_PATH = \"<PATH_TO_CIVIL_COMMENTS_READY_CSV>\"  # e.g., \"data/Civil_Comments_TFDS.csv\"\n",
        "\n",
        "# A pre-clean Golden Dataset file (spreadsheet) after human labeling ---\n",
        "GOLD_PRE_CLEAN_PATH = \"<PATH_TO_GOLDEN_PRECLEAN_XLSX>\"      # e.g., \"outputs/golden_dataset_preclean.xlsx\"\n",
        "GOLD_PRE_CLEAN_SHEET = \"golden_dataset\"\n",
        "\n",
        "# Outputs\n",
        "OUTPUT_DIR = \"outputs\"\n",
        "EXTRACTED_OUTPUT_PATH = f\"{OUTPUT_DIR}/golden_subset_extracted.csv\"\n",
        "CLEANED_OUTPUT_PATH  = f\"{OUTPUT_DIR}/golden_dataset_clean.xlsx\"\n",
        "\n",
        "print(\"Configured paths. Update the <...> placeholders before running.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def _is_placeholder(p: str) -> bool:\n",
        "    return isinstance(p, str) and p.strip().startswith(\"<\") and p.strip().endswith(\">\")\n",
        "\n",
        "# Create output directory early\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "if _is_placeholder(CIVIL_COMMENTS_PATH) or _is_placeholder(GOLD_PRE_CLEAN_PATH):\n",
        "    print(\"Update CIVIL_COMMENTS_PATH and GOLD_PRE_CLEAN_PATH before running the notebook.\")\n",
        "else:\n",
        "    print(\"Configured paths:\")\n",
        "    print(\" - CIVIL_COMMENTS_PATH =\", CIVIL_COMMENTS_PATH)\n",
        "    print(\" - GOLD_PRE_CLEAN_PATH =\", GOLD_PRE_CLEAN_PATH)\n",
        "    print(\" - OUTPUT_DIR          =\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "id": "yHe5pvqBaipJ"
      },
      "id": "yHe5pvqBaipJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f9322e2c",
      "metadata": {
        "id": "f9322e2c"
      },
      "source": [
        "## 1) Load Civil Comments source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e54253",
      "metadata": {
        "id": "b8e54253"
      },
      "outputs": [],
      "source": [
        "# Load the dataset used for extraction\n",
        "\n",
        "df = pd.read_csv(CIVIL_COMMENTS_PATH)\n",
        "\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", len(df.columns))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fb94fb0",
      "metadata": {
        "id": "9fb94fb0"
      },
      "source": [
        "## 2) Golden subset extraction / sampling (risk tiers + per-label minimums)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Golden Dataset Extraction\n",
        "\n",
        "This section constructs a small, governance-focused subset of the Civil Comments\n",
        "dataset.\n",
        "\n",
        "Sampling emphasizes:\n",
        "- borderline toxicity regions (high ambiguity)\n",
        "- clearly harmful cases\n",
        "- clearly non-harmful cases\n",
        "\n",
        "This design maximizes diagnostic value while keeping human labeling effort\n",
        "tractable.\n"
      ],
      "metadata": {
        "id": "UWa2hCkLVO1k"
      },
      "id": "UWa2hCkLVO1k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c168ea6",
      "metadata": {
        "id": "4c168ea6"
      },
      "outputs": [],
      "source": [
        "#Golden Dataset Sampling with Per-Label Minimums (≥ 15)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "label_cols = [\n",
        "    'toxicity', 'severe_toxicity', 'obscene',\n",
        "    'insult', 'threat', 'identity_attack', 'sexual_explicit'\n",
        "]\n",
        "\n",
        "# Targets by risk tier\n",
        "tier_targets = {'High-Risk': 186, 'Borderline': 62, 'Clean': 62}\n",
        "\n",
        "# Minimum presence per label (for analysis power):\n",
        "min_per_label = 15\n",
        "\n",
        "# Copy to avoid side effects\n",
        "pool = tiered_df.copy()\n",
        "\n",
        "# Track selections\n",
        "selected_idx = set()\n",
        "\n",
        "# Track how many we have taken from each tier so far\n",
        "tier_counts = {'High-Risk': 0, 'Borderline': 0, 'Clean': 0}\n",
        "\n",
        "# Sample rows safely from a candidate subset, honoring tier quotas and avoiding duplicates\n",
        "def take_from_pool(candidates, needed, tier_name):\n",
        "    \"\"\"Return a list of indices selected from 'candidates' up to 'needed',\n",
        "    without exceeding the remaining tier quota or duplicating rows.\"\"\"\n",
        "    remaining_quota = max(0, tier_targets[tier_name] - tier_counts[tier_name])\n",
        "    k = min(needed, remaining_quota, len(candidates))\n",
        "    if k <= 0:\n",
        "        return []\n",
        "    taken = candidates.sample(n=k, random_state=42).index.tolist()\n",
        "    return taken\n",
        "\n",
        "# Ensure ≥ 15 presence per label using High-Risk first (≥0.50), then Borderline (0.30–0.49)\n",
        "for L in label_cols:\n",
        "    # Count current presence already selected (initially 0)\n",
        "    def presence_mask(df):\n",
        "        return df[L] >= 0.30  # presence definition for later per-label analysis\n",
        "\n",
        "    current_presence = 0\n",
        "\n",
        "    # High-Risk pool for this label (presence AND risk_tier == 'High-Risk')\n",
        "    hr_pool = pool[\n",
        "        (pool.index.isin(selected_idx) == False) &\n",
        "        (pool['risk_tier'] == 'High-Risk') &\n",
        "        (pool[L] >= 0.50)\n",
        "    ]\n",
        "\n",
        "    # Take as many as possible toward the min requirement from High-Risk\n",
        "    need = max(0, min_per_label - current_presence)\n",
        "    hr_take = take_from_pool(hr_pool, need, 'High-Risk')\n",
        "    selected_idx.update(hr_take)\n",
        "    tier_counts['High-Risk'] += len(hr_take)\n",
        "    current_presence += len(hr_take)\n",
        "\n",
        "    # If still short, top up from Borderline presence (0.30–0.49) where risk_tier == 'Borderline'\n",
        "    if current_presence < min_per_label:\n",
        "        bl_pool = pool[\n",
        "            (pool.index.isin(selected_idx) == False) &\n",
        "            (pool['risk_tier'] == 'Borderline') &\n",
        "            (pool[L] >= 0.30) & (pool[L] < 0.50)\n",
        "        ]\n",
        "        need = max(0, min_per_label - current_presence)\n",
        "        bl_take = take_from_pool(bl_pool, need, 'Borderline')\n",
        "        selected_idx.update(bl_take)\n",
        "        tier_counts['Borderline'] += len(bl_take)\n",
        "        current_presence += len(bl_take)\n",
        "\n",
        "    # If still short (extremely rare labels), allow spillover from remaining High-Risk presence again,\n",
        "    # even if not dominant, as long as L >= 0.30 and risk_tier == 'High-Risk' (covers cases with another label slightly higher)\n",
        "    if current_presence < min_per_label:\n",
        "        hr_any_pool = pool[\n",
        "            (pool.index.isin(selected_idx) == False) &\n",
        "            (pool['risk_tier'] == 'High-Risk') &\n",
        "            (pool[L] >= 0.30)\n",
        "        ]\n",
        "        need = max(0, min_per_label - current_presence)\n",
        "        hr_any_take = take_from_pool(hr_any_pool, need, 'High-Risk')\n",
        "        selected_idx.update(hr_any_take)\n",
        "        tier_counts['High-Risk'] += len(hr_any_take)\n",
        "        current_presence += len(hr_any_take)\n",
        "\n",
        "    # NOTE: We do NOT pull presence from Clean for per-label minima,\n",
        "    # because presence ≥ 0.30 by definition belongs to High-Risk/Borderline thresholds.\n",
        "\n",
        "# After guaranteeing per-label minima, fill remaining quotas per tier at random (stratified only by tier).\n",
        "# This preserves organic composition while completing 186 / 62 / 62.\n",
        "for tier_name in ['High-Risk', 'Borderline', 'Clean']:\n",
        "    remaining = max(0, tier_targets[tier_name] - tier_counts[tier_name])\n",
        "    if remaining == 0:\n",
        "        continue\n",
        "\n",
        "    tier_pool = pool[\n",
        "        (pool.index.isin(selected_idx) == False) &\n",
        "        (pool['risk_tier'] == tier_name)\n",
        "    ]\n",
        "\n",
        "    # If the tier has fewer rows than needed, take all; otherwise sample\n",
        "    if len(tier_pool) <= remaining:\n",
        "        take_idx = tier_pool.index.tolist()\n",
        "    else:\n",
        "        take_idx = tier_pool.sample(n=remaining, random_state=42).index.tolist()\n",
        "\n",
        "    selected_idx.update(take_idx)\n",
        "    tier_counts[tier_name] += len(take_idx)\n",
        "\n",
        "# Build the final DataFrame, shuffle, and double-check totals\n",
        "golden_df = pool.loc[list(selected_idx)].sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Safety trims if overshoot (should not happen, but keep consistent with prior pattern)\n",
        "if len(golden_df) > 313:\n",
        "    golden_df = golden_df.sample(n=313, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Quick verification\n",
        "print(f\"Extracted Golden subset size: {len(golden_df)}\")\n",
        "print(\"Tier counts:\\n\", golden_df['risk_tier'].value_counts().to_string(), \"\\n\")\n",
        "\n",
        "# Per-label PRESENCE counts (rows where label score ≥ 0.30 anywhere in the row)\n",
        "presence_summary = {}\n",
        "for L in label_cols:\n",
        "    presence_summary[L] = int((golden_df[L] >= 0.30).sum())\n",
        "print(\"Per-label presence (≥ 0.30) counts:\\n\", pd.Series(presence_summary).to_string(), \"\\n\")\n",
        "\n",
        "# Show dominant_label cross-tab for context (not the enforcement metric)\n",
        "print(\"Dominant label distribution (context only):\\n\")\n",
        "print(golden_df['dominant_label'].value_counts().to_string())\n",
        "\n",
        "# Save final dataset\n",
        "golden_df.to_csv(EXTRACTED_OUTPUT_PATH, index=False)\n",
        "print(f\"Saved extracted Golden subset to: {EXTRACTED_OUTPUT_PATH}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbb40e5b",
      "metadata": {
        "id": "cbb40e5b"
      },
      "source": [
        "## 3) Load pre-clean Golden Dataset (after human labeling)\n",
        "\n",
        "This stage:\n",
        "- parses label list columns (e.g., `first_label`, `final_label`)\n",
        "- expands them into binary indicator columns\n",
        "- converts ambiguity text into numeric codes\n",
        "- drops helper/duplicate columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b591d31d",
      "metadata": {
        "id": "b591d31d"
      },
      "outputs": [],
      "source": [
        "# Load the labeled spreadsheet (pre-clean)\n",
        "# Make sure the sheet contains columns like: first_label, final_label, ambiguity, final_ambiguity\n",
        "df_gold = pd.read_excel(GOLD_PRE_CLEAN_PATH, sheet_name=GOLD_PRE_CLEAN_SHEET)\n",
        "\n",
        "print(\"Rows:\", len(df_gold))\n",
        "df_gold.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbea4bae",
      "metadata": {
        "id": "fbea4bae"
      },
      "outputs": [],
      "source": [
        "# If labels are stored as strings like \"['toxicity','insult']\" convert them to Python lists.\n",
        "\n",
        "import ast\n",
        "\n",
        "def to_list(x):\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        try:\n",
        "            return ast.literal_eval(x)\n",
        "        except Exception:\n",
        "            # fallback: split on commas if needed\n",
        "            return [t.strip() for t in x.strip(\"[]\").replace(\"'\", \"\").split(\",\") if t.strip()]\n",
        "    return []\n",
        "\n",
        "for col in [\"first_label\", \"final_label\"]:\n",
        "    if col in df_gold.columns:\n",
        "        df_gold[col] = df_gold[col].apply(to_list)\n",
        "\n",
        "df_gold[[\"first_label\",\"final_label\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Label Expansion\n",
        "\n",
        "Human annotations are expanded into analysis-ready columns, including:\n",
        "- binary harm indicators\n",
        "- ambiguity codes\n",
        "- standardized column names\n",
        "\n",
        "Explicit ambiguity handling is critical for governance-aligned evaluation and\n",
        "prevents treating contested cases as ground truth.\n"
      ],
      "metadata": {
        "id": "uMCbaFwAY5hD"
      },
      "id": "uMCbaFwAY5hD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d4de63a",
      "metadata": {
        "id": "4d4de63a"
      },
      "outputs": [],
      "source": [
        "# Expand label lists into binary columns\n",
        "ALL_LABELS = [\n",
        "    \"toxicity\", \"severe_toxicity\", \"obscene\",\n",
        "    \"insult\", \"threat\", \"identity_attack\", \"sexual_explicit\"\n",
        "]\n",
        "\n",
        "for label in ALL_LABELS:\n",
        "    df_gold[f\"first_{label}\"] = df_gold[\"first_label\"].apply(lambda lst: 1 if label in lst else 0)\n",
        "    df_gold[f\"final_{label}\"] = df_gold[\"final_label\"].apply(lambda lst: 1 if label in lst else 0)\n",
        "\n",
        "df_gold[[c for c in df_gold.columns if c.startswith(\"first_\") or c.startswith(\"final_\")]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b8d0e56",
      "metadata": {
        "id": "5b8d0e56"
      },
      "outputs": [],
      "source": [
        "# Convert ambiguity text into numeric codes\n",
        "ambiguity_map = {\n",
        "    \"no_violation\": 0,\n",
        "    \"gray_area\": 1,\n",
        "    \"clear_violation\": 2\n",
        "}\n",
        "\n",
        "if \"ambiguity\" in df_gold.columns:\n",
        "    df_gold[\"ambiguity_code\"] = df_gold[\"ambiguity\"].map(ambiguity_map)\n",
        "\n",
        "if \"final_ambiguity\" in df_gold.columns:\n",
        "    df_gold[\"final_ambiguity_code\"] = df_gold[\"final_ambiguity\"].map(ambiguity_map)\n",
        "\n",
        "df_gold[[c for c in [\"ambiguity\",\"final_ambiguity\",\"ambiguity_code\",\"final_ambiguity_code\"] if c in df_gold.columns]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Cleaning and Finalization\n",
        "\n",
        "This step standardizes column formats and prepares the dataset for evaluation.\n",
        "No content-level filtering is applied in order to preserve ambiguity.\n"
      ],
      "metadata": {
        "id": "oUFzM77YYt5B"
      },
      "id": "oUFzM77YYt5B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ccd28ac",
      "metadata": {
        "id": "4ccd28ac"
      },
      "outputs": [],
      "source": [
        "# Drop columns not needed in the final clean export\n",
        "COLUMNS_TO_DROP = [] # add any helper columns here if needed\n",
        "\n",
        "df_gold_clean = df_gold.drop(columns=COLUMNS_TO_DROP, errors=\"ignore\").copy()\n",
        "\n",
        "print(\"Clean columns:\", len(df_gold_clean.columns))\n",
        "df_gold_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Outputs\n",
        "\n",
        "Exported files are intentionally excluded from version control.\n",
        "This repository provides construction logic only and does not redistribute\n",
        "labeled datasets or raw comment text.\n"
      ],
      "metadata": {
        "id": "w-NZ9mOAYXBw"
      },
      "id": "w-NZ9mOAYXBw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e88cb361",
      "metadata": {
        "id": "e88cb361"
      },
      "outputs": [],
      "source": [
        "# Save cleaned Golden Dataset\n",
        "import os\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "df_gold_clean.to_excel(CLEANED_OUTPUT_PATH, index=False)\n",
        "print(\"Saved:\", CLEANED_OUTPUT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "This notebook documents the full construction of a governance-aligned Golden\n",
        "Dataset used to evaluate system risk in policy-driven AI systems.\n",
        "\n",
        "The dataset is designed for diagnostic evaluation rather than large-scale\n",
        "training and enables analysis of ambiguity, bias propagation, outcome disparity,\n",
        "and governance drift.\n"
      ],
      "metadata": {
        "id": "szweSbqWYP5P"
      },
      "id": "szweSbqWYP5P"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}